{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cd5a84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #used for importing\n",
    "import math as m \n",
    "import numpy as np #used for matrix manipulation\n",
    "from scipy.interpolate import interp2d #used for interpolating Perple_X outputs\n",
    "from scipy.interpolate import interp1d #used for interpolating evenly spaced P-T conditions from modeling\n",
    "from mpl_toolkits import mplot3d\n",
    "import matplotlib.pyplot as plt #plotting package\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap #used for defining user-created colormap\n",
    "import matplotlib.colors as col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ac00a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "##USER INPUTS------------------------------------------------------------------------------------------------------------\n",
    "##-----------------------------------------------------------------------------------------------------------------------\n",
    "##for P-T conditions used in Perplex Calculation. P-T range and nodes used in werami\n",
    "Tst=273\n",
    "Tend=1700\n",
    "Pst=1500\n",
    "Pend=80000\n",
    "nodes=250\n",
    "\n",
    "##thickness of layers in the downgoing section. should sum to 10100. The code extracts P-T data every 100m from slabtop\n",
    "##to 10km below, with each P-T path controlling devolatilization for the underlying 100m, hence the 10km P-T path dictates\n",
    "##devolatilization in the depth range of 10 to 10.1km\n",
    "lay_thk=[2100,5000,1400,300,300,0] #last value is for sediment thickness, which is changed later for each loop\n",
    "\n",
    "##creates arrays for setting up interpolation, Tmin to tmaxx with an increment matching that used in werami\n",
    "Tinc=(Tend-Tst)/(nodes-1)\n",
    "Pinc=(Pend-Pst)/(nodes-1)\n",
    "Tppx=np.arange(Tst,Tend+Tinc,Tinc)\n",
    "Pppx=np.arange(Pst,Pend+Pinc,Pinc)\n",
    "##----------------------------------------------------------------------------------------------------------------------\n",
    "##----------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "#This section reads in the Holt & Condit dataset and normalizes all ages steps to the same size, from xmin:xmax=500\n",
    "#this works for all time steps from 1 to 118, but can be defined by user to omit early steps (as done here)\n",
    "\n",
    "#create 4 dimensional indexing array\n",
    "#D1=surface, 5km, 10km\n",
    "#D2=X,Y,P_lith,P_tot,T\n",
    "#D3=idx_len=# of time steps considered, here we omit the first 7, beginning with t=5.6Myr, i.e. 8:118=111\n",
    "#D4=nromalized Xdistance=; inc=round((xmax-xmin-1)/500,3); X_new=np.arange(xmin,xmax,inc)==500\n",
    "t_start=8 #time step to begin with, here it is the 8th step, corresponding to t=5.6Myr\n",
    "idx_len=107 #max ages step included in input file\n",
    "data_mat_norm=np.zeros((3,5,idx_len,500))\n",
    "\n",
    "#define naming format\n",
    "file_slabtop='holt4e20/{}.slabtop.txt'\n",
    "file_5km='holt4e20/{}.5km.txt'\n",
    "file_10km='holt4e20/{}.10km.txt'\n",
    "\n",
    "#read in X,Y,P_lith,P_tot,T for each time step\n",
    "for i in range(t_start,idx_len+t_start): #t_start here signifies the starting t step\n",
    "    PT_st=pd.read_csv(file_slabtop.format(i), header=None, delim_whitespace=True)\n",
    "    PT_5k=pd.read_csv(file_5km.format(i), header=None, delim_whitespace=True)\n",
    "    PT_10k=pd.read_csv(file_10km.format(i), header=None, delim_whitespace=True)\n",
    "\n",
    "    #convert to numpy arrays\n",
    "    PT_st=PT_st.to_numpy()\n",
    "    PT_5k=PT_5k.to_numpy()\n",
    "    PT_10k=PT_10k.to_numpy()\n",
    "\n",
    "    #flips arrays to be ordered by increasing X\n",
    "    PT_st=np.flipud(PT_st)\n",
    "    PT_5k=np.flipud(PT_5k)\n",
    "    PT_10k=np.flipud(PT_10k)\n",
    "    \n",
    "    #determines length of each file for normalization\n",
    "    mxst=PT_st.shape[0]-1\n",
    "    mx5k=PT_5k.shape[0]-1\n",
    "    mx10k=PT_10k.shape[0]-1\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------------\n",
    "    xmin=m.ceil(PT_st[1,0]) #determines minimum X value at slabtop\n",
    "            \n",
    "    lmax_pos=0 # sets position of max X value for next loop\n",
    "    \n",
    "    #this loop iterates through the X data to determine if and where the X value starts appreciably decreasing. \n",
    "    #this step is required for interpolation as 1dinterp requires a monotonically increasing independent array\n",
    "    #the cutoff is set to be where the indexed X-value is greater than the next highest index X-value by a value of 5 \n",
    "    #value of 5 is somewhat arbitrary.\n",
    "    \n",
    "    #IF THIS BLOCK PRESENTS AN ERROR: print(i) AND INSPECT THE FILE TO SEE HOW TO CHANGE THE LOGIC. NOT THE BEST FIX\n",
    "    #BUT NEEDED DUE TO THE NATURE OF EXTRACTING CONTINUOUS DATA FROM FINITE ELEMENTS.\n",
    "    \n",
    "    for j in range(50,mxst):\n",
    "        if (((PT_st[j,0]>PT_st[j+1,0]) and (PT_st[j,0]-PT_st[j+1,0]>5)) or (PT_st[j,0]-PT_st[j+1,0]<-9)):\n",
    "            lmax_pos=j\n",
    "            break  \n",
    "            \n",
    "    #if there is no point where the previous loop is satisfied the index for the max X-value is set to the max index \n",
    "    #of the array        \n",
    "    if lmax_pos==0: \n",
    "        lmax_pos=mxst\n",
    "    \n",
    "    #determines the maximum X value at the previously determined index, and creates the X-range for 1dinterpolation\n",
    "    xmax=m.floor(PT_st[lmax_pos,0])\n",
    "    inc=round((xmax-xmin-1)/500,3)\n",
    "    X_new=np.arange(xmin,xmax,inc)\n",
    "\n",
    "    #In a few instances the X-range is longer than we want, so we resize by deleting the last few elements.\n",
    "    if X_new.shape[0]>500:\n",
    "        X_new=X_new[0:500]\n",
    "    \n",
    "    #creates the interpolation functions for Y, P_lith, P_tot, and T as a function of X\n",
    "    F_Yst=interp1d(PT_st[1:lmax_pos,0],PT_st[1:lmax_pos,1])\n",
    "    F_Plst=interp1d(PT_st[1:lmax_pos,0],PT_st[1:lmax_pos,2])\n",
    "    F_Ptst=interp1d(PT_st[1:lmax_pos,0],PT_st[1:lmax_pos,3])\n",
    "    F_Tst=interp1d(PT_st[1:lmax_pos,0],PT_st[1:lmax_pos,4])\n",
    "    \n",
    "    #determines the new values for Y, P_lith, P_tot, and T as a function of the new X-range\n",
    "    Y_new=F_Yst(X_new)\n",
    "    Pl_new=F_Plst(X_new)\n",
    "    Pt_new=F_Ptst(X_new)\n",
    "    T_new=F_Tst(X_new)\n",
    "    \n",
    "    #adds new values of X, Y, P_lith, P_tot, and T to the 4d array. The above section has only computed new values for\n",
    "    #the slabtop. The next two sections repeat the process for PT conditions at depths of 5 and 10km below the slabtop\n",
    "    #notice that the indexing shows i-1, this is because we have omitted the first time step from the matrix, it has a bunch\n",
    "    #of weird artifacts.\n",
    "    data_mat_norm[0,0,i-8,:]=X_new\n",
    "    data_mat_norm[0,1,i-8,:]=Y_new\n",
    "    data_mat_norm[0,2,i-8,:]=Pl_new\n",
    "    data_mat_norm[0,3,i-8,:]=Pt_new\n",
    "    data_mat_norm[0,4,i-8,:]=T_new\n",
    "#----------------------------------------------------------------------------------------------------------------\n",
    "#5km interpolation    \n",
    "    xmin=m.ceil(PT_5k[1,0])\n",
    "            \n",
    "    lmax_pos=0\n",
    "    \n",
    "    for j in range(50,mx5k):\n",
    "        if (((PT_5k[j,0]>PT_5k[j+1,0]) and (PT_5k[j,0]-PT_5k[j+1,0]>5)) or (PT_5k[j,0]-PT_5k[j+1,0]<-9)):\n",
    "            lmax_pos=j\n",
    "            break  \n",
    "            \n",
    "    if lmax_pos==0:\n",
    "        lmax_pos=mx5k\n",
    "        \n",
    "    xmax=m.floor(PT_5k[lmax_pos,0])\n",
    "    inc=round((xmax-xmin-1)/500,3)\n",
    "    X_new=np.arange(xmin,xmax,inc)\n",
    "\n",
    "    if X_new.shape[0]>500:\n",
    "        X_new=X_new[0:500]\n",
    "    #X_new=X_new[0:490]\n",
    "    \n",
    "    F_Y5k=interp1d(PT_5k[1:lmax_pos,0],PT_5k[1:lmax_pos,1])\n",
    "    F_Pl5k=interp1d(PT_5k[1:lmax_pos,0],PT_5k[1:lmax_pos,2])\n",
    "    F_Pt5k=interp1d(PT_5k[1:lmax_pos,0],PT_5k[1:lmax_pos,3])\n",
    "    F_T5k=interp1d(PT_5k[1:lmax_pos,0],PT_5k[1:lmax_pos,4])\n",
    "    \n",
    "    Y_new=F_Y5k(X_new)\n",
    "    Pl_new=F_Pl5k(X_new)\n",
    "    Pt_new=F_Pt5k(X_new)\n",
    "    T_new=F_T5k(X_new)\n",
    "    \n",
    "    data_mat_norm[1,0,i-8,:]=X_new\n",
    "    data_mat_norm[1,1,i-8,:]=Y_new\n",
    "    data_mat_norm[1,2,i-8,:]=Pl_new\n",
    "    data_mat_norm[1,3,i-8,:]=Pt_new\n",
    "    data_mat_norm[1,4,i-8,:]=T_new\n",
    "#----------------------------------------------------------------------------------------------------------------\n",
    "#10km interpolation\n",
    "    xmin=m.ceil(PT_10k[1,0])\n",
    "            \n",
    "    lmax_pos=0\n",
    "    \n",
    "    for j in range(50,mx10k):\n",
    "        if (((PT_10k[j,0]>PT_10k[j+1,0]) and (PT_10k[j,0]-PT_10k[j+1,0]>5)) or (PT_10k[j,0]-PT_10k[j+1,0]<-9)):\n",
    "            lmax_pos=j\n",
    "            break  \n",
    "            \n",
    "    if lmax_pos==0:\n",
    "        lmax_pos=mx10k\n",
    "        \n",
    "    xmax=m.floor(PT_10k[lmax_pos,0])\n",
    "    inc=round((xmax-xmin-1)/500,3)\n",
    "    X_new=np.arange(xmin,xmax,inc)\n",
    "\n",
    "    if X_new.shape[0]>500:\n",
    "        X_new=X_new[0:500]\n",
    "    #X_new=X_new[0:490]\n",
    "    \n",
    "    F_Y10k=interp1d(PT_10k[1:lmax_pos,0],PT_10k[1:lmax_pos,1])\n",
    "    F_Pl10k=interp1d(PT_10k[1:lmax_pos,0],PT_10k[1:lmax_pos,2])\n",
    "    F_Pt10k=interp1d(PT_10k[1:lmax_pos,0],PT_10k[1:lmax_pos,3])\n",
    "    F_T10k=interp1d(PT_10k[1:lmax_pos,0],PT_10k[1:lmax_pos,4])\n",
    "    \n",
    "    Y_new=F_Y10k(X_new)\n",
    "    Pl_new=F_Pl10k(X_new)\n",
    "    Pt_new=F_Pt10k(X_new)\n",
    "    T_new=F_T10k(X_new)\n",
    "    \n",
    "    data_mat_norm[2,0,i-8,:]=X_new\n",
    "    data_mat_norm[2,1,i-8,:]=Y_new\n",
    "    data_mat_norm[2,2,i-8,:]=Pl_new\n",
    "    data_mat_norm[2,3,i-8,:]=Pt_new\n",
    "    data_mat_norm[2,4,i-8,:]=T_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c405f861",
   "metadata": {},
   "outputs": [],
   "source": [
    "abmin=m.ceil(np.min(data_mat_norm[:,0,:,0])) #absolute minimum of all X-values\n",
    "abmax=m.floor(np.max(data_mat_norm[:,0,:,499])) #absolute maximum of all X-values\n",
    "even_inc=abmax-abmin\n",
    "xrange=np.arange(abmin,abmax) #indexing array used to find start and stop locations for filling D4 of array\n",
    "\n",
    "##loads in auxillary file which contains ages associated with the time steps. only loads age column\n",
    "age=pd.read_csv('holt4e20/age_convergence.txt', header=None, usecols=[1], delim_whitespace=True)\n",
    "age=age.to_numpy()\n",
    "##creates 2 array of ages for use in contour plotting\n",
    "age=np.repeat(age[8:idx_len+8],500,axis=1)\n",
    "\n",
    "convergence=pd.read_csv('holt4e20/age_convergence.txt', header=None, usecols=[2], delim_whitespace=True)\n",
    "convergence=convergence.to_numpy()\n",
    "##creates 2 array of ages for use in contour plotting\n",
    "convergence=np.repeat(convergence[8:idx_len+8],even_inc,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d78f634a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##This section creates a new 4d array and fills it with even spaced X,Y,P_tot,T data.\n",
    "##The array is first poulated with NaNs, its maximum dimension encompasses the entire X-range of all P-T paths in \n",
    "##1km increments (here 1300). For any given slab the array is populated only over a subset range, with the remaining array\n",
    "##elements retaining NaN.\n",
    "## The final results in a 4d array with: \n",
    "##D1=X,Y,P_tot,T\n",
    "##D2=in-slab data, from the interface to 10km depth with a spacing of 100m\n",
    "##D3=each individual time step from 1 to 118 (0 to 117 as index)\n",
    "##D4=km spacing over X-range, I have used indexing to fill the final matrix with data interpolated in the loops.\n",
    "\n",
    "array2=np.empty((4,101,idx_len,even_inc)) #creating of hypercube array\n",
    "array2[:]=np.nan #filling of array elements with NaN\n",
    "\n",
    "for k in range(0,idx_len): #ARE WE SURE THIS SHOULD ONLY GO TO idx_len???\n",
    "    \n",
    "    section=data_mat_norm[:,:,k,:]\n",
    "    min2=m.ceil(np.max(section[:,0,0]))\n",
    "    max2=m.floor(np.min(section[:,0,499]))\n",
    "    range2=np.arange(min2,max2)\n",
    "    \n",
    "    start=np.where(xrange==min2)[0][0]\n",
    "    stop=np.where(xrange==max2)[0][0]\n",
    "    \n",
    "    FYst=interp1d(section[0,0,:],section[0,1,:])\n",
    "    FY5k=interp1d(section[1,0,:],section[1,1,:])\n",
    "    FY10k=interp1d(section[2,0,:],section[2,1,:])\n",
    "    \n",
    "    FPst=interp1d(section[0,0,:],section[0,3,:])\n",
    "    FP5k=interp1d(section[1,0,:],section[1,3,:])\n",
    "    FP10k=interp1d(section[2,0,:],section[2,3,:])\n",
    "    \n",
    "    FTst=interp1d(section[0,0,:],section[0,4,:])\n",
    "    FT5k=interp1d(section[1,0,:],section[1,4,:])\n",
    "    FT10k=interp1d(section[2,0,:],section[2,4,:])\n",
    "    \n",
    "    Yst=FYst(range2)\n",
    "    Y5k=FY5k(range2)\n",
    "    Y10k=FY10k(range2)\n",
    "\n",
    "    Pst=FPst(range2)\n",
    "    P5k=FP5k(range2)\n",
    "    P10k=FP10k(range2)\n",
    "\n",
    "    Tst=FTst(range2)\n",
    "    T5k=FT5k(range2)\n",
    "    T10k=FT10k(range2)\n",
    "    \n",
    "    X_incremental=range2.T\n",
    "    X_incremental=X_incremental.reshape(X_incremental.shape[0],-1)\n",
    "    X_incremental=np.repeat(X_incremental,101,axis=1)\n",
    "    array2[0,:,k,start:stop]=X_incremental.T\n",
    "    \n",
    "    for l in range(0,101):\n",
    "        if l<51:\n",
    "            array2[1,l,k,start:stop]=((1-l/50)*Yst+l/50*Y5k)\n",
    "            array2[2,l,k,start:stop]=((1-l/50)*Pst+l/50*P5k)\n",
    "            array2[3,l,k,start:stop]=((1-l/50)*Tst+l/50*T5k)\n",
    "        else:\n",
    "            array2[1,l,k,start:stop]=((1-(l-50)/50)*Y5k+(l-50)/50*Y10k)\n",
    "            array2[2,l,k,start:stop]=((1-(l-50)/50)*P5k+(l-50)/50*P10k)\n",
    "            array2[3,l,k,start:stop]=((1-(l-50)/50)*T5k+(l-50)/50*T10k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c4c05c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##read in the werami output files for the layers of interest. In this simple case, we have used 5km of MORB over\n",
    "##5.1km of serpentinite. The werami output needs to be edited to remove all header info except the final column headers.\n",
    "##for this simple case the files contain info on rock densisty, fluid density, bound fluid, melt, and melt density\n",
    "##the first 2 columns of the werami files (corresponding to T and P) are not read in (usecols keyword).\n",
    "##delim_whitespace is always required for reading in werami files because the spacing between columns is non-uniform.\n",
    "\n",
    "#Below is latest and greatest perple_x outputs\n",
    "lay0a=pd.read_csv('holt2e20/terrigenous.tab', usecols=[2,3,4,5,6], delim_whitespace=True)\n",
    "lay0b=pd.read_csv('holt2e20/pelagic.tab', usecols=[2,3,4,5,6], delim_whitespace=True)\n",
    "lay0c=pd.read_csv('holt2e20/carbonate.tab', usecols=[2,3,4,5,6], delim_whitespace=True)\n",
    "lay0d=pd.read_csv('holt2e20/turbidite.tab', usecols=[2,3,4,5,6], delim_whitespace=True)\n",
    "lay0e=pd.read_csv('holt2e20/diatomite.tab', usecols=[2,3,4,5,6], delim_whitespace=True)\n",
    "lay1=pd.read_csv('holt2e20/ue90.tab', usecols=[2,3,4,5,6], delim_whitespace=True)\n",
    "lay2=pd.read_csv('holt2e20/le90.tab', usecols=[2,3,4,5,6], delim_whitespace=True)\n",
    "lay3=pd.read_csv('holt2e20/sd90.tab', usecols=[2,3,4,5,6], delim_whitespace=True)\n",
    "lay4=pd.read_csv('holt2e20/g90.tab', usecols=[2,3,4,5,6], delim_whitespace=True)\n",
    "lay5=pd.read_csv('holt2e20/hart_peridotite_new.tab', usecols=[2,3,4,5,6], delim_whitespace=True)\n",
    "\n",
    "##convert files to numpy arrays\n",
    "#sediment types\n",
    "lay0a=lay0a.to_numpy() #terrigenous\n",
    "lay0b=lay0b.to_numpy() #pelagic\n",
    "lay0c=lay0c.to_numpy() #carbonate\n",
    "lay0d=lay0d.to_numpy() #turbidite\n",
    "lay0e=lay0e.to_numpy() #diatomite\n",
    "\n",
    "#all other compositions\n",
    "lay1=lay1.to_numpy()\n",
    "lay2=lay2.to_numpy()\n",
    "lay3=lay3.to_numpy()\n",
    "lay4=lay4.to_numpy()\n",
    "lay5=lay5.to_numpy()\n",
    "\n",
    "##repeat the above processes for the other layer/layers read in from Perple_X\n",
    "lay0a_den=lay0a[:,0]\n",
    "lay0a_aqden=lay0a[:,1]\n",
    "lay0a_fl=lay0a[:,2]\n",
    "lay0a_melt=lay0a[:,3]\n",
    "lay0a_mden=lay0a[:,4]\n",
    "\n",
    "lay0a_den=lay0a_den.reshape(nodes,nodes)\n",
    "lay0a_aqden=lay0a_aqden.reshape(nodes,nodes)\n",
    "lay0a_fl=lay0a_fl.reshape(nodes,nodes)\n",
    "lay0a_melt=lay0a_melt.reshape(nodes,nodes)\n",
    "lay0a_mden=lay0a_mden.reshape(nodes,nodes)\n",
    "\n",
    "lay0a_den=np.nan_to_num(lay0a_den,nan=0)\n",
    "lay0a_aqden=np.nan_to_num(lay0a_aqden,nan=0)\n",
    "lay0a_fl=np.nan_to_num(lay0a_fl,nan=0)\n",
    "lay0a_melt=np.nan_to_num(lay0a_melt,nan=0)\n",
    "lay0a_mden=np.nan_to_num(lay0a_mden,nan=0)\n",
    "\n",
    "F_den_0a=interp2d(Tppx,Pppx,lay0a_den)\n",
    "F_aqden_0a=interp2d(Tppx,Pppx,lay0a_aqden)\n",
    "F_fl_0a=interp2d(Tppx,Pppx,lay0a_fl)\n",
    "F_melt_0a=interp2d(Tppx,Pppx,lay0a_melt)\n",
    "F_mden_0a=interp2d(Tppx,Pppx,lay0a_mden)\n",
    "\n",
    "##repeat the above processes for the other layer/layers read in from Perple_X\n",
    "lay0b_den=lay0b[:,0]\n",
    "lay0b_aqden=lay0b[:,1]\n",
    "lay0b_fl=lay0b[:,2]\n",
    "lay0b_melt=lay0b[:,3]\n",
    "lay0b_mden=lay0b[:,4]\n",
    "\n",
    "lay0b_den=lay0b_den.reshape(nodes,nodes)\n",
    "lay0b_aqden=lay0b_aqden.reshape(nodes,nodes)\n",
    "lay0b_fl=lay0b_fl.reshape(nodes,nodes)\n",
    "lay0b_melt=lay0b_melt.reshape(nodes,nodes)\n",
    "lay0b_mden=lay0b_mden.reshape(nodes,nodes)\n",
    "\n",
    "lay0b_den=np.nan_to_num(lay0b_den,nan=0)\n",
    "lay0b_aqden=np.nan_to_num(lay0b_aqden,nan=0)\n",
    "lay0b_fl=np.nan_to_num(lay0b_fl,nan=0)\n",
    "lay0b_melt=np.nan_to_num(lay0b_melt,nan=0)\n",
    "lay0b_mden=np.nan_to_num(lay0b_mden,nan=0)\n",
    "\n",
    "F_den_0b=interp2d(Tppx,Pppx,lay0b_den)\n",
    "F_aqden_0b=interp2d(Tppx,Pppx,lay0b_aqden)\n",
    "F_fl_0b=interp2d(Tppx,Pppx,lay0b_fl)\n",
    "F_melt_0b=interp2d(Tppx,Pppx,lay0b_melt)\n",
    "F_mden_0b=interp2d(Tppx,Pppx,lay0b_mden)\n",
    "\n",
    "##repeat the above processes for the other layer/layers read in from Perple_X\n",
    "lay0c_den=lay0c[:,0]\n",
    "lay0c_aqden=lay0c[:,1]\n",
    "lay0c_fl=lay0c[:,2]\n",
    "lay0c_melt=lay0c[:,3]\n",
    "lay0c_mden=lay0c[:,4]\n",
    "\n",
    "lay0c_den=lay0c_den.reshape(nodes,nodes)\n",
    "lay0c_aqden=lay0c_aqden.reshape(nodes,nodes)\n",
    "lay0c_fl=lay0c_fl.reshape(nodes,nodes)\n",
    "lay0c_melt=lay0c_melt.reshape(nodes,nodes)\n",
    "lay0c_mden=lay0c_mden.reshape(nodes,nodes)\n",
    "\n",
    "lay0c_den=np.nan_to_num(lay0c_den,nan=0)\n",
    "lay0c_aqden=np.nan_to_num(lay0c_aqden,nan=0)\n",
    "lay0c_fl=np.nan_to_num(lay0c_fl,nan=0)\n",
    "lay0c_melt=np.nan_to_num(lay0c_melt,nan=0)\n",
    "lay0c_mden=np.nan_to_num(lay0c_mden,nan=0)\n",
    "\n",
    "F_den_0c=interp2d(Tppx,Pppx,lay0c_den)\n",
    "F_aqden_0c=interp2d(Tppx,Pppx,lay0c_aqden)\n",
    "F_fl_0c=interp2d(Tppx,Pppx,lay0c_fl)\n",
    "F_melt_0c=interp2d(Tppx,Pppx,lay0c_melt)\n",
    "F_mden_0c=interp2d(Tppx,Pppx,lay0c_mden)\n",
    "\n",
    "##repeat the above processes for the other layer/layers read in from Perple_X\n",
    "lay0d_den=lay0d[:,0]\n",
    "lay0d_aqden=lay0d[:,1]\n",
    "lay0d_fl=lay0d[:,2]\n",
    "lay0d_melt=lay0d[:,3]\n",
    "lay0d_mden=lay0d[:,4]\n",
    "\n",
    "lay0d_den=lay0d_den.reshape(nodes,nodes)\n",
    "lay0d_aqden=lay0d_aqden.reshape(nodes,nodes)\n",
    "lay0d_fl=lay0d_fl.reshape(nodes,nodes)\n",
    "lay0d_melt=lay0d_melt.reshape(nodes,nodes)\n",
    "lay0d_mden=lay0d_mden.reshape(nodes,nodes)\n",
    "\n",
    "lay0d_den=np.nan_to_num(lay0d_den,nan=0)\n",
    "lay0d_aqden=np.nan_to_num(lay0d_aqden,nan=0)\n",
    "lay0d_fl=np.nan_to_num(lay0d_fl,nan=0)\n",
    "lay0d_melt=np.nan_to_num(lay0d_melt,nan=0)\n",
    "lay0d_mden=np.nan_to_num(lay0d_mden,nan=0)\n",
    "\n",
    "F_den_0d=interp2d(Tppx,Pppx,lay0d_den)\n",
    "F_aqden_0d=interp2d(Tppx,Pppx,lay0d_aqden)\n",
    "F_fl_0d=interp2d(Tppx,Pppx,lay0d_fl)\n",
    "F_melt_0d=interp2d(Tppx,Pppx,lay0d_melt)\n",
    "F_mden_0d=interp2d(Tppx,Pppx,lay0d_mden)\n",
    "\n",
    "##repeat the above processes for the other layer/layers read in from Perple_X\n",
    "lay0e_den=lay0e[:,0]\n",
    "lay0e_aqden=lay0e[:,1]\n",
    "lay0e_fl=lay0e[:,2]\n",
    "lay0e_melt=lay0e[:,3]\n",
    "lay0e_mden=lay0e[:,4]\n",
    "\n",
    "lay0e_den=lay0e_den.reshape(nodes,nodes)\n",
    "lay0e_aqden=lay0e_aqden.reshape(nodes,nodes)\n",
    "lay0e_fl=lay0e_fl.reshape(nodes,nodes)\n",
    "lay0e_melt=lay0e_melt.reshape(nodes,nodes)\n",
    "lay0e_mden=lay0e_mden.reshape(nodes,nodes)\n",
    "\n",
    "lay0e_den=np.nan_to_num(lay0e_den,nan=0)\n",
    "lay0e_aqden=np.nan_to_num(lay0e_aqden,nan=0)\n",
    "lay0e_fl=np.nan_to_num(lay0e_fl,nan=0)\n",
    "lay0e_melt=np.nan_to_num(lay0e_melt,nan=0)\n",
    "lay0e_mden=np.nan_to_num(lay0e_mden,nan=0)\n",
    "\n",
    "F_den_0e=interp2d(Tppx,Pppx,lay0e_den)\n",
    "F_aqden_0e=interp2d(Tppx,Pppx,lay0e_aqden)\n",
    "F_fl_0e=interp2d(Tppx,Pppx,lay0e_fl)\n",
    "F_melt_0e=interp2d(Tppx,Pppx,lay0e_melt)\n",
    "F_mden_0e=interp2d(Tppx,Pppx,lay0e_mden)\n",
    "\n",
    "##split file into individual properties\n",
    "lay1_den=lay1[:,0]\n",
    "lay1_aqden=lay1[:,1]\n",
    "lay1_fl=lay1[:,2]\n",
    "lay1_melt=lay1[:,3]\n",
    "lay1_mden=lay1[:,4]\n",
    "\n",
    "\n",
    "##reshape individual files onto square grid [node,node]=[250,250] here\n",
    "lay1_den=lay1_den.reshape(nodes,nodes)\n",
    "lay1_aqden=lay1_aqden.reshape(nodes,nodes)\n",
    "lay1_fl=lay1_fl.reshape(nodes,nodes)\n",
    "lay1_melt=lay1_melt.reshape(nodes,nodes)\n",
    "lay1_mden=lay1_mden.reshape(nodes,nodes)\n",
    "\n",
    "##replace NaN with 0. Could be done in perple_X itself as well, but here we do it in post.\n",
    "lay1_den=np.nan_to_num(lay1_den,nan=0)\n",
    "lay1_aqden=np.nan_to_num(lay1_aqden,nan=0)\n",
    "lay1_fl=np.nan_to_num(lay1_fl,nan=0)\n",
    "lay1_melt=np.nan_to_num(lay1_melt,nan=0)\n",
    "lay1_mden=np.nan_to_num(lay1_mden,nan=0)\n",
    "\n",
    "##Create the interpolation functions for density, fluid density, bound H2O, melt, and melt density\n",
    "F_den_1=interp2d(Tppx,Pppx,lay1_den)\n",
    "F_aqden_1=interp2d(Tppx,Pppx,lay1_aqden)\n",
    "F_fl_1=interp2d(Tppx,Pppx,lay1_fl)\n",
    "F_melt_1=interp2d(Tppx,Pppx,lay1_melt)\n",
    "F_mden_1=interp2d(Tppx,Pppx,lay1_mden)\n",
    "\n",
    "##repeat the above processes for the other layer/layers read in from Perple_X\n",
    "lay2_den=lay2[:,0]\n",
    "lay2_aqden=lay2[:,1]\n",
    "lay2_fl=lay2[:,2]\n",
    "lay2_melt=lay2[:,3]\n",
    "lay2_mden=lay2[:,4]\n",
    "\n",
    "lay2_den=lay2_den.reshape(nodes,nodes)\n",
    "lay2_aqden=lay2_aqden.reshape(nodes,nodes)\n",
    "lay2_fl=lay2_fl.reshape(nodes,nodes)\n",
    "lay2_melt=lay2_melt.reshape(nodes,nodes)\n",
    "lay2_mden=lay2_mden.reshape(nodes,nodes)\n",
    "\n",
    "lay2_den=np.nan_to_num(lay2_den,nan=0)\n",
    "lay2_aqden=np.nan_to_num(lay2_aqden,nan=0)\n",
    "lay2_fl=np.nan_to_num(lay2_fl,nan=0)\n",
    "lay2_melt=np.nan_to_num(lay2_melt,nan=0)\n",
    "lay2_mden=np.nan_to_num(lay2_mden,nan=0)\n",
    "\n",
    "F_den_2=interp2d(Tppx,Pppx,lay2_den)\n",
    "F_aqden_2=interp2d(Tppx,Pppx,lay2_aqden)\n",
    "F_fl_2=interp2d(Tppx,Pppx,lay2_fl)\n",
    "F_melt_2=interp2d(Tppx,Pppx,lay2_melt)\n",
    "F_mden_2=interp2d(Tppx,Pppx,lay2_mden)\n",
    "\n",
    "##repeat the above processes for the other layer/layers read in from Perple_X\n",
    "lay3_den=lay3[:,0]\n",
    "lay3_aqden=lay3[:,1]\n",
    "lay3_fl=lay3[:,2]\n",
    "lay3_melt=lay3[:,3]\n",
    "lay3_mden=lay3[:,4]\n",
    "\n",
    "lay3_den=lay3_den.reshape(nodes,nodes)\n",
    "lay3_aqden=lay3_aqden.reshape(nodes,nodes)\n",
    "lay3_fl=lay3_fl.reshape(nodes,nodes)\n",
    "lay3_melt=lay3_melt.reshape(nodes,nodes)\n",
    "lay3_mden=lay3_mden.reshape(nodes,nodes)\n",
    "\n",
    "lay3_den=np.nan_to_num(lay3_den,nan=0)\n",
    "lay3_aqden=np.nan_to_num(lay3_aqden,nan=0)\n",
    "lay3_fl=np.nan_to_num(lay3_fl,nan=0)\n",
    "lay3_melt=np.nan_to_num(lay3_melt,nan=0)\n",
    "lay3_mden=np.nan_to_num(lay3_mden,nan=0)\n",
    "\n",
    "F_den_3=interp2d(Tppx,Pppx,lay3_den)\n",
    "F_aqden_3=interp2d(Tppx,Pppx,lay3_aqden)\n",
    "F_fl_3=interp2d(Tppx,Pppx,lay3_fl)\n",
    "F_melt_3=interp2d(Tppx,Pppx,lay3_melt)\n",
    "F_mden_3=interp2d(Tppx,Pppx,lay3_mden)\n",
    "\n",
    "##repeat the above processes for the other layer/layers read in from Perple_X\n",
    "lay4_den=lay4[:,0]\n",
    "lay4_aqden=lay4[:,1]\n",
    "lay4_fl=lay4[:,2]\n",
    "lay4_melt=lay4[:,3]\n",
    "lay4_mden=lay4[:,4]\n",
    "\n",
    "lay4_den=lay4_den.reshape(nodes,nodes)\n",
    "lay4_aqden=lay4_aqden.reshape(nodes,nodes)\n",
    "lay4_fl=lay4_fl.reshape(nodes,nodes)\n",
    "lay4_melt=lay4_melt.reshape(nodes,nodes)\n",
    "lay4_mden=lay4_mden.reshape(nodes,nodes)\n",
    "\n",
    "lay4_den=np.nan_to_num(lay4_den,nan=0)\n",
    "lay4_aqden=np.nan_to_num(lay4_aqden,nan=0)\n",
    "lay4_fl=np.nan_to_num(lay4_fl,nan=0)\n",
    "lay4_melt=np.nan_to_num(lay4_melt,nan=0)\n",
    "lay4_mden=np.nan_to_num(lay4_mden,nan=0)\n",
    "\n",
    "F_den_4=interp2d(Tppx,Pppx,lay4_den)\n",
    "F_aqden_4=interp2d(Tppx,Pppx,lay4_aqden)\n",
    "F_fl_4=interp2d(Tppx,Pppx,lay4_fl)\n",
    "F_melt_4=interp2d(Tppx,Pppx,lay4_melt)\n",
    "F_mden_4=interp2d(Tppx,Pppx,lay4_mden)\n",
    "\n",
    "##repeat the above processes for the other layer/layers read in from Perple_X\n",
    "lay5_den=lay5[:,0]\n",
    "lay5_aqden=lay5[:,1]\n",
    "lay5_fl=lay5[:,2]\n",
    "lay5_melt=lay5[:,3]\n",
    "lay5_mden=lay5[:,4]\n",
    "\n",
    "lay5_den=lay5_den.reshape(nodes,nodes)\n",
    "lay5_aqden=lay5_aqden.reshape(nodes,nodes)\n",
    "lay5_fl=lay5_fl.reshape(nodes,nodes)\n",
    "lay5_melt=lay5_melt.reshape(nodes,nodes)\n",
    "lay5_mden=lay5_mden.reshape(nodes,nodes)\n",
    "\n",
    "lay5_den=np.nan_to_num(lay5_den,nan=0)\n",
    "lay5_aqden=np.nan_to_num(lay5_aqden,nan=0)\n",
    "lay5_fl=np.nan_to_num(lay5_fl,nan=0)\n",
    "lay5_melt=np.nan_to_num(lay5_melt,nan=0)\n",
    "lay5_mden=np.nan_to_num(lay5_mden,nan=0)\n",
    "\n",
    "F_den_5=interp2d(Tppx,Pppx,lay5_den)\n",
    "F_aqden_5=interp2d(Tppx,Pppx,lay5_aqden)\n",
    "F_fl_5=interp2d(Tppx,Pppx,lay5_fl)\n",
    "F_melt_5=interp2d(Tppx,Pppx,lay5_melt)\n",
    "F_mden_5=interp2d(Tppx,Pppx,lay5_mden)\n",
    "\n",
    "##create nan array to be filled later, this will contain all interpolated outputs, and can be used in tandem with array2 \n",
    "##for plotting\n",
    "wedges_brc=np.empty((56,107))\n",
    "wedges_brc[:]=np.nan\n",
    "wedges_ant=np.empty((56,107))\n",
    "wedges_ant[:]=np.nan\n",
    "wedges_700=np.empty((56,107))\n",
    "wedges_700[:]=np.nan\n",
    "wedges_chl=np.empty((56,107))\n",
    "wedges_chl[:]=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e1df44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "h2o_capacity=pd.read_csv('Syracuse_Abers_margins.txt', delim_whitespace=True)\n",
    "h2o_capacity=h2o_capacity.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eaac05c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "wedge=pd.read_csv('wedge_PT/niu_perid_h2o_rho.tab', usecols=[2,3], delim_whitespace=True)\n",
    "wedge=wedge.to_numpy()\n",
    "wedge_fl=wedge[:,0]\n",
    "wedge_fl=wedge_fl.reshape(nodes,nodes)\n",
    "wedge_fl=np.nan_to_num(wedge_fl,nan=0)\n",
    "F_fl_wedge=interp2d(Tppx,Pppx,wedge_fl)\n",
    "\n",
    "wedge_out=np.empty((1,1,idx_len,even_inc))\n",
    "wedge_out[:]=np.nan\n",
    "for i in range(0,idx_len):\n",
    "    xlow=np.where(xrange==np.nanmin(array2[0,:,i,:]))[0][0]\n",
    "    xhigh=np.where(xrange==np.nanmax(array2[0,:,i,:]))[0][0]\n",
    "    ##water content of serp at interface-----------------------------------------------------------------\n",
    "    wedge_out[0,0,i,xlow:xhigh]=np.diag(F_fl_wedge(array2[3,0,i,xlow:xhigh]+273.15,array2[2,0,i,xlow:xhigh]*10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c70e6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n"
     ]
    }
   ],
   "source": [
    "#perform analysis for every syracuse margin, progress is output by showing margin number from 0 to 55; takes a few minutes\n",
    "\n",
    "for h in range(0,56):\n",
    "    ppx_out=np.empty((7,101,idx_len,even_inc))\n",
    "    ppx_out[:]=np.nan\n",
    "    \n",
    "    lay_thk[5]=h2o_capacity[h,1]\n",
    "\n",
    "    thk_steps=int((sum(lay_thk)-100)/100)\n",
    "\n",
    "    j1=int(lay_thk[0]/100)\n",
    "    j2=int((lay_thk[0]+lay_thk[1])/100)\n",
    "    j3=int((lay_thk[0]+lay_thk[1]+lay_thk[2])/100)\n",
    "    j4=int((lay_thk[0]+lay_thk[1]+lay_thk[2]+lay_thk[3])/100)\n",
    "    j5=int((lay_thk[0]+lay_thk[1]+lay_thk[2]+lay_thk[3]+lay_thk[4])/100)\n",
    "    j6=int((lay_thk[0]+lay_thk[1]+lay_thk[2]+lay_thk[3]+lay_thk[4]+lay_thk[5])/100)\n",
    "    \n",
    "    for i in range(0,idx_len):\n",
    "        xlow=np.where(xrange==np.nanmin(array2[0,:,i,:]))[0][0]\n",
    "        xhigh=np.where(xrange==np.nanmax(array2[0,:,i,:]))[0][0]\n",
    "        \n",
    "        for j in range(0,j1):\n",
    "            mm=thk_steps-j\n",
    "            path_den=F_den_5(array2[3,mm,i,xlow:xhigh]+273.15, array2[2,mm,i,xlow:xhigh]*10000) #den of serp (no fluid)\n",
    "            path_aqden=F_aqden_5(array2[3,mm,i,xlow:xhigh]+273.15, array2[2,mm,i,xlow:xhigh]*10000) #density of fluid\n",
    "            path_fl=F_fl_5(array2[3,mm,i,xlow:xhigh]+273.15, array2[2,mm,i,xlow:xhigh]*10000) #bound H2O wt%\n",
    "            path_melt=F_melt_5(array2[3,mm,i,xlow:xhigh]+273.15, array2[2,mm,i,xlow:xhigh]*10000) #melt wt% (no fluid)\n",
    "            path_mden=F_mden_5(array2[3,mm,i,xlow:xhigh]+273.15, array2[2,mm,i,xlow:xhigh]*10000) #melt den (no fluid)\n",
    "        \n",
    "            ppx_out[0,mm,i,xlow:xhigh]=np.diag(path_den)#den of serp (no fluid)\n",
    "            ppx_out[1,mm,i,xlow:xhigh]=np.diag(path_aqden)#density of fluid\n",
    "            ppx_out[2,mm,i,xlow:xhigh]=np.diag(path_fl)#bound H2O wt%\n",
    "            ppx_out[3,mm,i,xlow:xhigh]=np.diag(path_melt)#melt wt% (no fluid)\n",
    "            ppx_out[4,mm,i,xlow:xhigh]=np.diag(path_mden)#melt den (no fluid)\n",
    "            \n",
    "            ##if melt present than fluid content is removed from ppx_out\n",
    "            for n in range(xlow,xhigh+1):\n",
    "                if ppx_out[3,mm,i,n]>0:\n",
    "                    ppx_out[2,mm,i,n]=0\n",
    "            ##determines the kg of bound H2O/m3 using density and bound H2O wt%\n",
    "            ppx_out[5,mm,i,xlow:xhigh]=np.multiply(ppx_out[0,mm,i,xlow:xhigh],ppx_out[2,mm,i,xlow:xhigh])/100\n",
    "            for o in range(xlow+1,xhigh+1):\n",
    "                if ppx_out[5,mm,i,o]>ppx_out[5,mm,i,o-1]:\n",
    "                    ppx_out[5,mm,i,o]=ppx_out[5,mm,i,o-1]\n",
    "            ##determines incremental production of H2O in kg/m3        \n",
    "            ppx_out[6,mm,i,xlow+1:xhigh]=np.subtract(ppx_out[5,mm,i,xlow+1:xhigh],ppx_out[5,mm,i,xlow:xhigh-1])*-1\n",
    "\n",
    "        ##repeats the above for the upper layer (here MORB)\n",
    "        for j in range(j1,j2):\n",
    "            mm=thk_steps-j\n",
    "            path_den=F_den_4(array2[3,mm,i,xlow:xhigh]+273.15, array2[2,mm,i,xlow:xhigh]*10000) #den of serp (no fluid)\n",
    "            path_aqden=F_aqden_4(array2[3,mm,i,xlow:xhigh]+273.15, array2[2,mm,i,xlow:xhigh]*10000) #density of fluid\n",
    "            path_fl=F_fl_4(array2[3,mm,i,xlow:xhigh]+273.15, array2[2,mm,i,xlow:xhigh]*10000) #bound H2O wt%\n",
    "            path_melt=F_melt_4(array2[3,mm,i,xlow:xhigh]+273.15, array2[2,mm,i,xlow:xhigh]*10000) #melt wt% (no fluid)\n",
    "            path_mden=F_mden_4(array2[3,mm,i,xlow:xhigh]+273.15, array2[2,mm,i,xlow:xhigh]*10000) #melt den (no fluid)\n",
    "        \n",
    "            ppx_out[0,mm,i,xlow:xhigh]=np.diag(path_den)#den of serp (no fluid)\n",
    "            ppx_out[1,mm,i,xlow:xhigh]=np.diag(path_aqden)#density of fluid\n",
    "            ppx_out[2,mm,i,xlow:xhigh]=np.diag(path_fl)#bound H2O wt%\n",
    "            ppx_out[3,mm,i,xlow:xhigh]=np.diag(path_melt)#melt wt% (no fluid)\n",
    "            ppx_out[4,mm,i,xlow:xhigh]=np.diag(path_mden)#melt den (no fluid)\n",
    "        \n",
    "            for n in range(xlow,xhigh+1):\n",
    "                if ppx_out[3,mm,i,n]>0:\n",
    "                    ppx_out[2,mm,i,n]=0\n",
    "\n",
    "            ppx_out[5,mm,i,xlow:xhigh]=np.multiply(ppx_out[0,mm,i,xlow:xhigh],ppx_out[2,mm,i,xlow:xhigh])/100\n",
    "            for o in range(xlow+1,xhigh+1):\n",
    "                if ppx_out[5,mm,i,o]>ppx_out[5,mm,i,o-1]:\n",
    "                    ppx_out[5,mm,i,o]=ppx_out[5,mm,i,o-1]\n",
    "                \n",
    "            ppx_out[6,mm,i,xlow+1:xhigh]=np.subtract(ppx_out[5,mm,i,xlow+1:xhigh],ppx_out[5,mm,i,xlow:xhigh-1])*-1\n",
    "            \n",
    "        for j in range(j2,j3):\n",
    "            mm=thk_steps-j\n",
    "            path_den=F_den_3(array2[3,mm,i,xlow:xhigh]+273.15, array2[2,mm,i,xlow:xhigh]*10000) #den of serp (no fluid)\n",
    "            path_aqden=F_aqden_3(array2[3,mm,i,xlow:xhigh]+273.15, array2[2,mm,i,xlow:xhigh]*10000) #density of fluid\n",
    "            path_fl=F_fl_3(array2[3,mm,i,xlow:xhigh]+273.15, array2[2,mm,i,xlow:xhigh]*10000) #bound H2O wt%\n",
    "            path_melt=F_melt_3(array2[3,mm,i,xlow:xhigh]+273.15, array2[2,mm,i,xlow:xhigh]*10000) #melt wt% (no fluid)\n",
    "            path_mden=F_mden_3(array2[3,mm,i,xlow:xhigh]+273.15, array2[2,mm,i,xlow:xhigh]*10000) #melt den (no fluid)\n",
    "        \n",
    "            ppx_out[0,mm,i,xlow:xhigh]=np.diag(path_den)#den of serp (no fluid)\n",
    "            ppx_out[1,mm,i,xlow:xhigh]=np.diag(path_aqden)#density of fluid\n",
    "            ppx_out[2,mm,i,xlow:xhigh]=np.diag(path_fl)#bound H2O wt%\n",
    "            ppx_out[3,mm,i,xlow:xhigh]=np.diag(path_melt)#melt wt% (no fluid)\n",
    "            ppx_out[4,mm,i,xlow:xhigh]=np.diag(path_mden)#melt den (no fluid)\n",
    "        \n",
    "            ##if melt present than fluid content is removed from ppx_out\n",
    "            for n in range(xlow,xhigh+1):\n",
    "                if ppx_out[3,mm,i,n]>0:\n",
    "                    ppx_out[2,mm,i,n]=0\n",
    "            ##determines the kg of bound H2O/m3 using density and bound H2O wt%\n",
    "            ppx_out[5,mm,i,xlow:xhigh]=np.multiply(ppx_out[0,mm,i,xlow:xhigh],ppx_out[2,mm,i,xlow:xhigh])/100\n",
    "            for o in range(xlow+1,xhigh+1):\n",
    "                if ppx_out[5,mm,i,o]>ppx_out[5,mm,i,o-1]:\n",
    "                    ppx_out[5,mm,i,o]=ppx_out[5,mm,i,o-1]\n",
    "            ##determines incremental production of H2O in kg/m3        \n",
    "            ppx_out[6,mm,i,xlow+1:xhigh]=np.subtract(ppx_out[5,mm,i,xlow+1:xhigh],ppx_out[5,mm,i,xlow:xhigh-1])*-1\n",
    "            \n",
    "        for j in range(j3,j4):\n",
    "            mm=thk_steps-j\n",
    "            path_den=F_den_2(array2[3,mm,i,xlow:xhigh]+273.15, array2[2,mm,i,xlow:xhigh]*10000) #den of serp (no fluid)\n",
    "            path_aqden=F_aqden_2(array2[3,mm,i,xlow:xhigh]+273.15, array2[2,mm,i,xlow:xhigh]*10000) #density of fluid\n",
    "            path_fl=F_fl_2(array2[3,mm,i,xlow:xhigh]+273.15, array2[2,mm,i,xlow:xhigh]*10000) #bound H2O wt%\n",
    "            path_melt=F_melt_2(array2[3,mm,i,xlow:xhigh]+273.15, array2[2,mm,i,xlow:xhigh]*10000) #melt wt% (no fluid)\n",
    "            path_mden=F_mden_2(array2[3,mm,i,xlow:xhigh]+273.15, array2[2,mm,i,xlow:xhigh]*10000) #melt den (no fluid)\n",
    "        \n",
    "            ppx_out[0,mm,i,xlow:xhigh]=np.diag(path_den)#den of serp (no fluid)\n",
    "            ppx_out[1,mm,i,xlow:xhigh]=np.diag(path_aqden)#density of fluid\n",
    "            ppx_out[2,mm,i,xlow:xhigh]=np.diag(path_fl)#bound H2O wt%\n",
    "            ppx_out[3,mm,i,xlow:xhigh]=np.diag(path_melt)#melt wt% (no fluid)\n",
    "            ppx_out[4,mm,i,xlow:xhigh]=np.diag(path_mden)#melt den (no fluid)\n",
    "        \n",
    "            ##if melt present than fluid content is removed from ppx_out\n",
    "            for n in range(xlow,xhigh+1):\n",
    "                if ppx_out[3,mm,i,n]>0:\n",
    "                    ppx_out[2,mm,i,n]=0\n",
    "            ##determines the kg of bound H2O/m3 using density and bound H2O wt%\n",
    "            ppx_out[5,mm,i,xlow:xhigh]=np.multiply(ppx_out[0,mm,i,xlow:xhigh],ppx_out[2,mm,i,xlow:xhigh])/100\n",
    "            for o in range(xlow+1,xhigh+1):\n",
    "                if ppx_out[5,mm,i,o]>ppx_out[5,mm,i,o-1]:\n",
    "                    ppx_out[5,mm,i,o]=ppx_out[5,mm,i,o-1]\n",
    "            ##determines incremental production of H2O in kg/m3        \n",
    "            ppx_out[6,mm,i,xlow+1:xhigh]=np.subtract(ppx_out[5,mm,i,xlow+1:xhigh],ppx_out[5,mm,i,xlow:xhigh-1])*-1\n",
    "            \n",
    "        for j in range(j4,j5):\n",
    "            mm=thk_steps-j\n",
    "            path_den=F_den_1(array2[3,mm,i,xlow:xhigh]+273.15, array2[2,mm,i,xlow:xhigh]*10000) #den of serp (no fluid)\n",
    "            path_aqden=F_aqden_1(array2[3,mm,i,xlow:xhigh]+273.15, array2[2,mm,i,xlow:xhigh]*10000) #density of fluid\n",
    "            path_fl=F_fl_1(array2[3,mm,i,xlow:xhigh]+273.15, array2[2,mm,i,xlow:xhigh]*10000) #bound H2O wt%\n",
    "            path_melt=F_melt_1(array2[3,mm,i,xlow:xhigh]+273.15, array2[2,mm,i,xlow:xhigh]*10000) #melt wt% (no fluid)\n",
    "            path_mden=F_mden_1(array2[3,mm,i,xlow:xhigh]+273.15, array2[2,mm,i,xlow:xhigh]*10000) #melt den (no fluid)\n",
    "        \n",
    "            ppx_out[0,mm,i,xlow:xhigh]=np.diag(path_den)#den of serp (no fluid)\n",
    "            ppx_out[1,mm,i,xlow:xhigh]=np.diag(path_aqden)#density of fluid\n",
    "            ppx_out[2,mm,i,xlow:xhigh]=np.diag(path_fl)#bound H2O wt%\n",
    "            ppx_out[3,mm,i,xlow:xhigh]=np.diag(path_melt)#melt wt% (no fluid)\n",
    "            ppx_out[4,mm,i,xlow:xhigh]=np.diag(path_mden)#melt den (no fluid)\n",
    "        \n",
    "            ##if melt present than fluid content is removed from ppx_out\n",
    "            for n in range(xlow,xhigh+1):\n",
    "                if ppx_out[3,mm,i,n]>0:\n",
    "                    ppx_out[2,mm,i,n]=0\n",
    "            ##determines the kg of bound H2O/m3 using density and bound H2O wt%\n",
    "            ppx_out[5,mm,i,xlow:xhigh]=np.multiply(ppx_out[0,mm,i,xlow:xhigh],ppx_out[2,mm,i,xlow:xhigh])/100\n",
    "            for o in range(xlow+1,xhigh+1):\n",
    "                if ppx_out[5,mm,i,o]>ppx_out[5,mm,i,o-1]:\n",
    "                    ppx_out[5,mm,i,o]=ppx_out[5,mm,i,o-1]\n",
    "            ##determines incremental production of H2O in kg/m3        \n",
    "            ppx_out[6,mm,i,xlow+1:xhigh]=np.subtract(ppx_out[5,mm,i,xlow+1:xhigh],ppx_out[5,mm,i,xlow:xhigh-1])*-1\n",
    "            \n",
    "        for j in range(j5,j6):\n",
    "            mm=thk_steps-j\n",
    "            if h2o_capacity[h,2]==1:\n",
    "                path_den=F_den_0a(array2[3,mm,i,xlow:xhigh]+273.15, array2[2,mm,i,xlow:xhigh]*10000) #den of serp (no fluid)\n",
    "                path_aqden=F_aqden_0a(array2[3,mm,i,xlow:xhigh]+273.15, array2[2,mm,i,xlow:xhigh]*10000) #density of fluid\n",
    "                path_fl=F_fl_0a(array2[3,mm,i,xlow:xhigh]+273.15, array2[2,mm,i,xlow:xhigh]*10000) #bound H2O wt%\n",
    "                path_melt=F_melt_0a(array2[3,mm,i,xlow:xhigh]+273.15, array2[2,mm,i,xlow:xhigh]*10000) #melt wt% (no fluid)\n",
    "                path_mden=F_mden_0a(array2[3,mm,i,xlow:xhigh]+273.15, array2[2,mm,i,xlow:xhigh]*10000) #melt den (no fluid)\n",
    "            elif h2o_capacity[h,2]==2:\n",
    "                path_den=F_den_0b(array2[3,mm,i,xlow:xhigh]+273.15, array2[2,mm,i,xlow:xhigh]*10000) #den of serp (no fluid)\n",
    "                path_aqden=F_aqden_0b(array2[3,mm,i,xlow:xhigh]+273.15, array2[2,mm,i,xlow:xhigh]*10000) #density of fluid\n",
    "                path_fl=F_fl_0b(array2[3,mm,i,xlow:xhigh]+273.15, array2[2,mm,i,xlow:xhigh]*10000) #bound H2O wt%\n",
    "                path_melt=F_melt_0b(array2[3,mm,i,xlow:xhigh]+273.15, array2[2,mm,i,xlow:xhigh]*10000) #melt wt% (no fluid)\n",
    "                path_mden=F_mden_0b(array2[3,mm,i,xlow:xhigh]+273.15, array2[2,mm,i,xlow:xhigh]*10000) #melt den (no fluid)\n",
    "            elif h2o_capacity[h,2]==3:\n",
    "                path_den=F_den_0c(array2[3,mm,i,xlow:xhigh]+273.15, array2[2,mm,i,xlow:xhigh]*10000) #den of serp (no fluid)\n",
    "                path_aqden=F_aqden_0c(array2[3,mm,i,xlow:xhigh]+273.15, array2[2,mm,i,xlow:xhigh]*10000) #density of fluid\n",
    "                path_fl=F_fl_0c(array2[3,mm,i,xlow:xhigh]+273.15, array2[2,mm,i,xlow:xhigh]*10000) #bound H2O wt%\n",
    "                path_melt=F_melt_0c(array2[3,mm,i,xlow:xhigh]+273.15, array2[2,mm,i,xlow:xhigh]*10000) #melt wt% (no fluid)\n",
    "                path_mden=F_mden_0c(array2[3,mm,i,xlow:xhigh]+273.15, array2[2,mm,i,xlow:xhigh]*10000) #melt den (no fluid)\n",
    "            elif h2o_capacity[h,2]==4:\n",
    "                path_den=F_den_0d(array2[3,mm,i,xlow:xhigh]+273.15, array2[2,mm,i,xlow:xhigh]*10000) #den of serp (no fluid)\n",
    "                path_aqden=F_aqden_0d(array2[3,mm,i,xlow:xhigh]+273.15, array2[2,mm,i,xlow:xhigh]*10000) #density of fluid\n",
    "                path_fl=F_fl_0d(array2[3,mm,i,xlow:xhigh]+273.15, array2[2,mm,i,xlow:xhigh]*10000) #bound H2O wt%\n",
    "                path_melt=F_melt_0d(array2[3,mm,i,xlow:xhigh]+273.15, array2[2,mm,i,xlow:xhigh]*10000) #melt wt% (no fluid)\n",
    "                path_mden=F_mden_0d(array2[3,mm,i,xlow:xhigh]+273.15, array2[2,mm,i,xlow:xhigh]*10000) #melt den (no fluid)\n",
    "            else:\n",
    "                path_den=F_den_0e(array2[3,mm,i,xlow:xhigh]+273.15, array2[2,mm,i,xlow:xhigh]*10000) #den of serp (no fluid)\n",
    "                path_aqden=F_aqden_0e(array2[3,mm,i,xlow:xhigh]+273.15, array2[2,mm,i,xlow:xhigh]*10000) #density of fluid\n",
    "                path_fl=F_fl_0e(array2[3,mm,i,xlow:xhigh]+273.15, array2[2,mm,i,xlow:xhigh]*10000) #bound H2O wt%\n",
    "                path_melt=F_melt_0e(array2[3,mm,i,xlow:xhigh]+273.15, array2[2,mm,i,xlow:xhigh]*10000) #melt wt% (no fluid)\n",
    "                path_mden=F_mden_0e(array2[3,mm,i,xlow:xhigh]+273.15, array2[2,mm,i,xlow:xhigh]*10000) #melt den (no fluid)\n",
    "                \n",
    "            ppx_out[0,mm,i,xlow:xhigh]=np.diag(path_den)#den of serp (no fluid)\n",
    "            ppx_out[1,mm,i,xlow:xhigh]=np.diag(path_aqden)#density of fluid\n",
    "            ppx_out[2,mm,i,xlow:xhigh]=np.diag(path_fl)#bound H2O wt%\n",
    "            ppx_out[3,mm,i,xlow:xhigh]=np.diag(path_melt)#melt wt% (no fluid)\n",
    "            ppx_out[4,mm,i,xlow:xhigh]=np.diag(path_mden)#melt den (no fluid)\n",
    "        \n",
    "            ##if melt present than fluid content is removed from ppx_out\n",
    "            for n in range(xlow,xhigh+1):\n",
    "                if ppx_out[3,mm,i,n]>0:\n",
    "                    ppx_out[2,mm,i,n]=0\n",
    "            ##determines the kg of bound H2O/m3 using density and bound H2O wt%\n",
    "            ppx_out[5,mm,i,xlow:xhigh]=np.multiply(ppx_out[0,mm,i,xlow:xhigh],ppx_out[2,mm,i,xlow:xhigh])/100\n",
    "            for o in range(xlow+1,xhigh+1):\n",
    "                if ppx_out[5,mm,i,o]>ppx_out[5,mm,i,o-1]:\n",
    "                    ppx_out[5,mm,i,o]=ppx_out[5,mm,i,o-1]\n",
    "            ##determines incremental production of H2O in kg/m3        \n",
    "            ppx_out[6,mm,i,xlow+1:xhigh]=np.subtract(ppx_out[5,mm,i,xlow+1:xhigh],ppx_out[5,mm,i,xlow:xhigh-1])*-1\n",
    "##-------------------------------------------------------------------------------------------------------------------------\n",
    "##-------------------------------------------------------------------------------------------------------------------------\n",
    "    dip_rad=np.empty((idx_len,even_inc))\n",
    "    dip_rad[:]=np.nan\n",
    "    for i in range(0,idx_len):\n",
    "        xlow=np.where(xrange==np.nanmin(array2[0,:,i,:]))[0][0]\n",
    "        xhigh=np.where(xrange==np.nanmax(array2[0,:,i,:]))[0][0]\n",
    "        for j in range(xlow+1,xhigh+1):\n",
    "            dip_rad[i,j]=m.atan(array2[1,0,i,j]-array2[1,0,i,j-1])\n",
    "        dip_rad[i,xlow]=dip_rad[i,xlow+1]\n",
    "    app_sr=np.multiply(np.cos(dip_rad),convergence)/100\n",
    "    \n",
    "    map_fl_mass=np.zeros((idx_len,even_inc))\n",
    "    for i in range(0,idx_len):\n",
    "        xlow=np.where(xrange==np.nanmin(array2[0,:,i,:]))[0][0]\n",
    "        xhigh=np.where(xrange==np.nanmax(array2[0,:,i,:]))[0][0]\n",
    "        t_i=np.subtract(array2[1,100,i,xlow:xhigh],array2[1,0,i,xlow:xhigh])*10\n",
    "        fluid_col=np.sum(ppx_out[6,0:thk_steps+1,i,xlow:xhigh],axis=0)\n",
    "        map_fl_mass[i,xlow:xhigh]=np.multiply(fluid_col,t_i)\n",
    "\n",
    "    d700=np.zeros((idx_len,))\n",
    "    dbrc=np.zeros((idx_len,))\n",
    "    dant=np.zeros((idx_len,))\n",
    "    dchl=np.zeros((idx_len,))\n",
    "    for i in range(0,idx_len):\n",
    "        d700[i,]=array2[1,0,i,np.where(array2[3,0,i,:]>=700)[0][0]]\n",
    "        dbrc[i,]=array2[1,0,i,np.where(wedge_out[0,0,i,:]<=8)[0][0]]\n",
    "        dant[i,]=array2[1,0,i,np.where(wedge_out[0,0,i,:]<=4)[0][0]]\n",
    "        dchl[i,]=array2[1,0,i,np.where(wedge_out[0,0,i,:]<=1)[0][0]]\n",
    "        \n",
    "    forearc_flux_delt_brc=np.zeros((idx_len,even_inc))\n",
    "    for i in range(0,idx_len):\n",
    "        xlow=np.where(array2[1,0,i,:]>=30)[0][0]\n",
    "        if np.nanmax(array2[1,0,i,:])>80:\n",
    "            if dbrc[i]<=80:\n",
    "                xhigh=np.where(array2[1,0,i,:]>=dbrc[i])[0][0]\n",
    "            else:\n",
    "                xhigh=np.where(array2[1,0,i,:]>=80)[0][0]\n",
    "        else:\n",
    "            xhigh=np.where(xrange==np.nanmax(array2[0,:,i,:]))[0][0] \n",
    "        forearc_flux_delt_brc[i,xlow:xhigh]=np.multiply(map_fl_mass[i,xlow:xhigh],app_sr[i,xlow:xhigh])\n",
    "\n",
    "    forearc_flux_delt_ant=np.zeros((idx_len,even_inc))\n",
    "    for i in range(0,idx_len):\n",
    "        xlow=np.where(array2[1,0,i,:]>=30)[0][0]\n",
    "        if np.nanmax(array2[1,0,i,:])>80:\n",
    "            if dant[i]<=80:\n",
    "                xhigh=np.where(array2[1,0,i,:]>=dant[i])[0][0]\n",
    "            else:\n",
    "                xhigh=np.where(array2[1,0,i,:]>=80)[0][0]\n",
    "        else:\n",
    "            xhigh=np.where(xrange==np.nanmax(array2[0,:,i,:]))[0][0] \n",
    "        forearc_flux_delt_ant[i,xlow:xhigh]=np.multiply(map_fl_mass[i,xlow:xhigh],app_sr[i,xlow:xhigh])\n",
    "\n",
    "    forearc_flux_delt_700=np.zeros((idx_len,even_inc))\n",
    "    for i in range(0,idx_len):\n",
    "        xlow=np.where(array2[1,0,i,:]>=30)[0][0]\n",
    "        if np.nanmax(array2[1,0,i,:])>80:\n",
    "            if d700[i]<=80:\n",
    "                xhigh=np.where(array2[1,0,i,:]>=d700[i])[0][0]\n",
    "            else:\n",
    "                xhigh=np.where(array2[1,0,i,:]>=80)[0][0]\n",
    "        else:\n",
    "            xhigh=np.where(xrange==np.nanmax(array2[0,:,i,:]))[0][0] \n",
    "        forearc_flux_delt_700[i,xlow:xhigh]=np.multiply(map_fl_mass[i,xlow:xhigh],app_sr[i,xlow:xhigh])\n",
    "\n",
    "    forearc_flux_delt_chl=np.zeros((idx_len,even_inc))\n",
    "    for i in range(0,idx_len):\n",
    "        xlow=np.where(array2[1,0,i,:]>=30)[0][0]\n",
    "        if np.nanmax(array2[1,0,i,:])>80:\n",
    "            if dchl[i]<=80:\n",
    "                xhigh=np.where(array2[1,0,i,:]>=dchl[i])[0][0]\n",
    "            else:\n",
    "                xhigh=np.where(array2[1,0,i,:]>=80)[0][0]\n",
    "        else:\n",
    "            xhigh=np.where(xrange==np.nanmax(array2[0,:,i,:]))[0][0] \n",
    "        forearc_flux_delt_chl[i,xlow:xhigh]=np.multiply(map_fl_mass[i,xlow:xhigh],app_sr[i,xlow:xhigh])\n",
    "        \n",
    "        \n",
    "    forearc_delt_tot_brc=np.nansum(forearc_flux_delt_brc,axis=1)\n",
    "    wedges_brc[h,:]=forearc_delt_tot_brc\n",
    "    forearc_delt_tot_ant=np.nansum(forearc_flux_delt_ant,axis=1)\n",
    "    wedges_ant[h,:]=forearc_delt_tot_ant\n",
    "    forearc_delt_tot_700=np.nansum(forearc_flux_delt_700,axis=1)\n",
    "    wedges_700[h,:]=forearc_delt_tot_700\n",
    "    forearc_delt_tot_chl=np.nansum(forearc_flux_delt_chl,axis=1)\n",
    "    wedges_chl[h,:]=forearc_delt_tot_chl\n",
    "    print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "92e1e7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('holt4e20/wedges_brc_4e20.txt',wedges_brc)\n",
    "np.savetxt('holt4e20/wedges_ant_4e20.txt',wedges_ant)\n",
    "np.savetxt('holt4e20/wedges_700_4e20.txt',wedges_700)\n",
    "np.savetxt('holt4e20/wedges_chl_4e20.txt',wedges_chl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4d2d98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
